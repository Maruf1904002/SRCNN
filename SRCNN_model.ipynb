{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMncKHxwuukJ/LlOr4MFVGM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruf1904002/SRCNN/blob/main/SRCNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shoDq_AH3M4L"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "!pip install tensorflow tensorboardX\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Conv2D, Input, Add, PReLU, BatchNormalization, Dropout, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.image import ssim\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n"
      ],
      "metadata": {
        "id": "NSDstX1B3TTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Add, PReLU, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.image import ssim\n",
        "\n",
        "# Custom SSIM + MSE loss for RGB images\n",
        "def ssim_mse_loss(y_true, y_pred):\n",
        "    ssim_loss = 1 - tf.reduce_mean(ssim(y_true, y_pred, max_val=1.0))\n",
        "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    return 0.7 * ssim_loss + 0.3 * mse_loss\n",
        "\n",
        "# Improved SRCNN Architecture\n",
        "def improved_srcnn():\n",
        "    inputs = Input(shape=(None, None, 1))  # Grayscale input\n",
        "\n",
        "    x = Conv2D(64, (9, 9), padding='same')(inputs)\n",
        "    # x = BatchNormalization()(x)\n",
        "    x = PReLU(shared_axes=[1, 2])(x)\n",
        "\n",
        "    for _ in range(2):  # 2 Residual Blocks\n",
        "        res = Conv2D(64, (3, 3), padding='same')(x)\n",
        "        res = BatchNormalization()(res)\n",
        "        res = PReLU(shared_axes=[1, 2])(res)\n",
        "        res = Conv2D(64, (3, 3), padding='same')(res)\n",
        "        res = BatchNormalization()(res)\n",
        "        x = Add()([x, res])\n",
        "        x = PReLU(shared_axes=[1, 2])(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "    outputs = Conv2D(1, (3, 3), padding='same', activation='sigmoid')(x)  # RGB output\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    optimizer = Adam(learning_rate=0.5, decay=0)\n",
        "    model.compile(optimizer=optimizer, loss=ssim_mse_loss, metrics=['mse'])\n",
        "    return model\n",
        "\n",
        "# Instantiate and summarize\n",
        "model = improved_srcnn()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "fBV83nhq3WPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "\n",
        "# Paths to zip files in Drive\n",
        "zip_hr = '/content/drive/MyDrive/DIV2K_Patches/patches_HR.zip'\n",
        "zip_lr = '/content/drive/MyDrive/DIV2K_Patches/patches_LR.zip'\n",
        "\n",
        "# Extract folders if not already done\n",
        "if not os.path.exists('/content/DIV2K_HR'):\n",
        "    with zipfile.ZipFile(zip_hr, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/DIV2K_HR')\n",
        "if not os.path.exists('/content/DIV2K_LR'):\n",
        "    with zipfile.ZipFile(zip_lr, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/DIV2K_LR')\n",
        "\n",
        "print(\"ZIPs extracted\")\n",
        "\n",
        "# Set dataset paths\n",
        "hr_path = '/content/DIV2K_HR/patches_HR'\n",
        "lr_path = '/content/DIV2K_LR/patches_LR'\n",
        "\n",
        "# Get sorted file names (assumes matching order)\n",
        "hr_files = sorted([os.path.join(hr_path, f) for f in os.listdir(hr_path) if f.endswith('.png')])\n",
        "lr_files = sorted([os.path.join(lr_path, f) for f in os.listdir(lr_path) if f.endswith('.png')])\n",
        "\n",
        "# Split into training and validation\n",
        "split = int(len(hr_files) * 0.9)\n",
        "train_hr_files, val_hr_files = hr_files[:split], hr_files[split:]\n",
        "train_lr_files, val_lr_files = lr_files[:split], lr_files[split:]\n",
        "\n",
        "# Resize shape (match to what your model expects â€” 96x96 recommended)\n",
        "resize_shape = [96, 96]\n",
        "\n",
        "# Function to load and resize both LR and HR to same shape\n",
        "def load_image_pair(lr_path, hr_path):\n",
        "    lr_img = tf.io.read_file(lr_path)\n",
        "    lr_img = tf.image.decode_png(lr_img, channels=1)\n",
        "    lr_img = tf.image.convert_image_dtype(lr_img, tf.float32)\n",
        "    lr_img = tf.image.resize(lr_img, resize_shape)\n",
        "\n",
        "    hr_img = tf.io.read_file(hr_path)\n",
        "    hr_img = tf.image.decode_png(hr_img, channels=1)\n",
        "    hr_img = tf.image.convert_image_dtype(hr_img, tf.float32)\n",
        "    hr_img = tf.image.resize(hr_img, resize_shape)\n",
        "\n",
        "    return lr_img, hr_img\n",
        "\n",
        "# Slice training data before dataset is created\n",
        "train_hr_files = train_hr_files[:50000]\n",
        "train_lr_files = train_lr_files[:50000]\n",
        "\n",
        "# limit validation time\n",
        "val_hr_files = val_hr_files[:40000]\n",
        "val_lr_files = val_lr_files[:40000]\n",
        "\n",
        "# Build TensorFlow datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_lr_files, train_hr_files))\n",
        "train_ds = train_ds.map(load_image_pair).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_lr_files, val_hr_files))\n",
        "val_ds = val_ds.map(load_image_pair).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"âœ… Prepared {len(train_hr_files)} training pairs, {len(val_hr_files)} validation pairs\")\n"
      ],
      "metadata": {
        "id": "-GKYb3_S3ZRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
        "\n",
        "# Set up callbacks\n",
        "log_dir = \"/content/logs\"  # Save logs locally (faster than Drive)\n",
        "# tensorboard_cb = TensorBoard(log_dir=log_dir)\n",
        "tensorboard_cb = TensorBoard(log_dir=log_dir, write_graph=False, write_images=False)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=1e-4, verbose=1)\n",
        "\n",
        "# Run training (config for 50 epoch)\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=50,\n",
        "                    callbacks=[lr_scheduler])\n",
        "\n",
        "# Save locally (quick, safe)\n",
        "model.save(\"improved_srcnn_local.h5\")\n",
        "\n",
        "print(\"Training + model save completed.\")\n"
      ],
      "metadata": {
        "id": "zjmLtwJ83dSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pkX4DiWy3gcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "\n",
        "def psnr(y_true, y_pred):\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1.0).numpy()\n",
        "\n",
        "# sample from validation set\n",
        "for lr_batch, hr_batch in val_ds.take(1):\n",
        "    sample_lr = lr_batch[0:1]      # (1, H, W, 1)\n",
        "    sample_hr = hr_batch[0]        # (H, W, 1)\n",
        "\n",
        "sample_sr = model.predict(sample_lr)[0]  # (H, W, 1)\n",
        "\n",
        "print(\"PSNR:\", psnr(sample_hr, sample_sr))\n",
        "\n",
        "# Plot the results\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axs[0].imshow(sample_lr[0, :, :, 0], cmap='gray')\n",
        "axs[0].set_title(\"Low-Res\")\n",
        "axs[1].imshow(sample_sr[:, :, 0], cmap='gray')\n",
        "axs[1].set_title(\"Super-Resolved\")\n",
        "axs[2].imshow(sample_hr[:, :, 0], cmap='gray')\n",
        "axs[2].set_title(\"Ground Truth\")\n",
        "for ax in axs: ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3yuQgWv63jQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.image import ssim\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_metrics_on_validation(val_ds, model):\n",
        "    psnr_list, ssim_list = [], []\n",
        "\n",
        "    for lr_batch, hr_batch in val_ds:\n",
        "        for i in range(lr_batch.shape[0]):\n",
        "            lr_img = tf.expand_dims(lr_batch[i], axis=0)\n",
        "            hr_img = hr_batch[i]\n",
        "            sr_img = model.predict(lr_img, verbose=0)[0]\n",
        "\n",
        "            psnr_val = tf.image.psnr(hr_img, sr_img, max_val=1.0).numpy()\n",
        "            ssim_val = ssim(hr_img, sr_img, max_val=1.0).numpy()\n",
        "\n",
        "            psnr_list.append(psnr_val)\n",
        "            ssim_list.append(ssim_val)\n",
        "\n",
        "    return psnr_list, ssim_list\n",
        "\n",
        "# Run and store\n",
        "psnr_scores, ssim_scores = evaluate_metrics_on_validation(val_ds, model)\n",
        "\n",
        "# Convert to NumPy for stats and plotting\n",
        "psnr_scores = np.array(psnr_scores)\n",
        "ssim_scores = np.array(ssim_scores)\n",
        "\n",
        "# Plot graphs\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(psnr_scores, label='PSNR', color='tab:blue')\n",
        "plt.xlabel(\"Image Index\")\n",
        "plt.ylabel(\"PSNR (dB)\")\n",
        "plt.title(\"PSNR Across Validation Set\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(ssim_scores, label='SSIM', color='tab:green')\n",
        "plt.xlabel(\"Image Index\")\n",
        "plt.ylabel(\"SSIM\")\n",
        "plt.title(\"SSIM Across Validation Set\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Box plots\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.boxplot([psnr_scores, ssim_scores], labels=['PSNR', 'SSIM'])\n",
        "plt.title(\"Distribution of PSNR and SSIM\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Summary stat\n",
        "print(f\"ðŸ“Š PSNR - Mean: {psnr_scores.mean():.2f}, Max: {psnr_scores.max():.2f}, Min: {psnr_scores.min():.2f}\")\n",
        "print(f\"ðŸ“Š SSIM - Mean: {ssim_scores.mean():.4f}, Max: {ssim_scores.max():.4f}, Min: {ssim_scores.min():.4f}\")\n"
      ],
      "metadata": {
        "id": "8xto1b4K3pFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "results_df = pd.DataFrame({\n",
        "    'Image #': list(range(1, len(psnr_scores) + 1)),\n",
        "    'PSNR': np.round(psnr_scores, 3),\n",
        "    'SSIM': np.round(ssim_scores, 3)\n",
        "})\n",
        "display(results_df)\n",
        "results_df.to_csv(\"/content/drive/MyDrive/DIV2K/validation_metrics.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "rZn1tKor3sfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get sample from val_ds\n",
        "for lr_batch, hr_batch in val_ds.take(1):\n",
        "    lr_img = tf.expand_dims(lr_batch[0], axis=0)  # (1, H, W, 1)\n",
        "    hr_img = hr_batch[0]                          # (H, W, 1)\n",
        "\n",
        "# Predict\n",
        "sr_img = model.predict(lr_img, verbose=0)[0]      # (H, W, 1)\n",
        "\n",
        "# Compute error map\n",
        "error_map = np.abs(hr_img.numpy() - sr_img)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(hr_img[:, :, 0], cmap='gray')\n",
        "plt.title(\"Ground Truth\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(sr_img[:, :, 0], cmap='gray')\n",
        "plt.title(\"Super-Resolved\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(error_map[:, :, 0], cmap='hot')\n",
        "plt.title(\"Error Map\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RzrXMyh63v2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert to NumPy\n",
        "hr_np = hr_img.numpy()[:, :, 0]\n",
        "sr_np = sr_img[:, :, 0]\n",
        "\n",
        "# Compute SSIM and get the full SSIM map\n",
        "ssim_score, ssim_map = compare_ssim(hr_np, sr_np, full=True, data_range=1.0)\n",
        "\n",
        "\n",
        "# Plot SSIM heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(ssim_map, cmap='viridis')\n",
        "plt.title(f\"SSIM Heatmap (score: {ssim_score:.4f})\")\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "11a0uYDx3yfc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}